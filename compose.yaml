services:
  whisperx-api-server-cuda:
    image: whisperx-api-server-cuda
    build:
      context: .
      dockerfile: Dockerfile.cuda
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8000/healthcheck || exit 1"]
    command: uvicorn --factory whisperx_api_server.main:create_app --reload --host 0.0.0.0
    ports:
      - 8000:8000
    volumes:
      - hugging_face_cache:/root/.cache/huggingface
      - torch_cache:/root/.cache/torch
      - ./src/whisperx_api_server:/workspace/whisperx_api_server:Z
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    devices:
      - nvidia.com/gpu=all
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - PYTHONDONTWRITEBYTECODE=1
      - WHISPER__MODEL=deepdml/faster-whisper-large-v3-turbo-ct2
      - WHISPER__COMPUTE_TYPE=int8
  whisperx-api-server-cpu:
    image: whisperx-api-server-cpu
    build:
      context: .
      dockerfile: Dockerfile.cpu
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8000/healthcheck || exit 1"]
    command: uvicorn --factory whisperx_api_server.main:create_app
    ports:
      - 8000:8000
    volumes:
      - hugging_face_cache:/root/.cache/huggingface
      - torch_cache:/root/.cache/torch
volumes:
  hugging_face_cache:
  torch_cache: